{"cells":[{"cell_type":"markdown","source":["Aluna: Manuela de Lacerda Bezerra Carvalho (mlbc@cesar.school)"],"metadata":{"id":"TVrdt_0f-HZc"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"ypctkg9WlE7E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735948451709,"user_tz":180,"elapsed":17172,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"6db5cccf-e450-4276-ec25-3c784735c3f0"},"outputs":[{"name":"stdout","output_type":"stream","text":["··········\n"]}],"source":["import getpass\n","import os\n","\n","os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"]},{"cell_type":"markdown","metadata":{"id":"l8Sbty6FlE7U"},"source":["## Retrieval Augmented Generation (RAG)"]},{"cell_type":"markdown","metadata":{"id":"Qeo8zXCilE7c"},"source":["### Carregando Documentos - Loading"]},{"cell_type":"code","source":["!pip install langchain-community"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"8ZtOfsq0m1Lj","executionInfo":{"status":"ok","timestamp":1735948512080,"user_tz":180,"elapsed":12694,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"d18a4ed6-0fdc-4073-aa7e-035f96b1f5bd"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain-community\n","  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.36)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.10)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n","  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n","Collecting langchain<0.4.0,>=0.3.14 (from langchain-community)\n","  Downloading langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n","Collecting langchain-core<0.4.0,>=0.3.29 (from langchain-community)\n","  Downloading langchain_core-0.3.29-py3-none-any.whl.metadata (6.3 kB)\n","Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.3)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n","Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n","  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Downloading marshmallow-3.23.3-py3-none-any.whl.metadata (7.1 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (0.3.3)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (2.10.3)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.12)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n","Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-community) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community) (2.27.1)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.2.2)\n","Downloading langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n","Downloading langchain-0.3.14-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.3.29-py3-none-any.whl (411 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n","Downloading marshmallow-3.23.3-py3-none-any.whl (48 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain-community\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.3.25\n","    Uninstalling langchain-core-0.3.25:\n","      Successfully uninstalled langchain-core-0.3.25\n","  Attempting uninstall: langchain\n","    Found existing installation: langchain 0.3.12\n","    Uninstalling langchain-0.3.12:\n","      Successfully uninstalled langchain-0.3.12\n","Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.14 langchain-community-0.3.14 langchain-core-0.3.29 marshmallow-3.23.3 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"natSmedvlE7f","executionInfo":{"status":"ok","timestamp":1735948916514,"user_tz":180,"elapsed":1576,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"8b5bbab5-012f-4d8f-d151-61e32ba8ec4c"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"]},{"output_type":"execute_result","data":{"text/plain":["4301"]},"metadata":{},"execution_count":6}],"source":["# https://python.langchain.com/v0.2/docs/how_to/#document-loaders\n","# https://python.langchain.com/v0.2/docs/integrations/document_loaders/\n","\n","import bs4\n","from langchain_community.document_loaders import WebBaseLoader\n","\n","# Filtra o conteúdo da página por uma classe específica\n","bs4_strainer = bs4.SoupStrainer(class_=(\"container-wrapper\"))\n","\n","# Carrega o conteúdo da página\n","loader = WebBaseLoader(\n","    web_paths=(\"https://cesar.breezy.hr/p/00f79174d8ad-pesquisador-em-inteligencia-artificial-e-sistemas-distribuidos\",),\n","    bs_kwargs={\"parse_only\": bs4_strainer},\n",")\n","\n","# Carrega o conteúdo da página\n","docs = loader.load()\n","\n","len(docs[0].page_content)"]},{"cell_type":"markdown","metadata":{"id":"dM5i6S5clE7i"},"source":["### Dividindo Documentos - Splitting/Chunking"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tT2T9dUMlE7k","executionInfo":{"status":"ok","timestamp":1735948920546,"user_tz":180,"elapsed":368,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"0b4a3c31-b582-47d1-fff3-6e0c2060c724"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["6"]},"metadata":{},"execution_count":7}],"source":["# https://python.langchain.com/v0.2/docs/how_to/#text-splitters\n","\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=1000, chunk_overlap=500, add_start_index=True\n",")\n","all_splits = text_splitter.split_documents(docs)\n","\n","len(all_splits)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2jt2dADElE7l","executionInfo":{"status":"ok","timestamp":1735321440836,"user_tz":180,"elapsed":331,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"cd66e9fa-519b-4b2d-9ee5-f0808469fa8e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requisitos e Qualificações:\n","Doutorado em áreas correlatas;Compreenda e desenvolva modelos de machine learning e deep learning para resolver desafios complexos de cibersegurança;Conhecimento em frameworks de machine learning como TensorFlow, PyTorch ou scikit-learn para desenvolver modelos preditivos e de detecção de anomalias aplicados à cibersegurança;Entenda a arquitetura distribuída dos sistemas e garanta a integração eficiente de soluções de IA com aplicações em cloud;Habilidade em manipulação e visualização de dados com Pandas, NumPy, Matplotlib e Seaborn para explorar grandes volumes de dados;Experiência com AWS, Google Cloud ou Azure para projetar e implementar infraestruturas escaláveis e resilientes;Familiaridade com Kubernetes e Docker para garantir escalabilidade e resiliência de sistemas distribuídos;Experiência com controle de versão (Git) e repositórios remotos como GitLab;Inglês avançado para leitura, escrita e comunicação, facilitando a colaboração com equipes globais.\n"]}],"source":["print(all_splits[3].page_content)"]},{"cell_type":"markdown","metadata":{"id":"GO47SaNJlE7n"},"source":["### Indexando - Store"]},{"cell_type":"code","source":["!pip install langchain-openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"NEwiVD63rtXR","executionInfo":{"status":"ok","timestamp":1735948832820,"user_tz":180,"elapsed":5283,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"77bbe05a-ad47-4e61-c038-7764219ef89e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain-openai\n","  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.3.29)\n","Collecting openai<2.0.0,>=1.58.1 (from langchain-openai)\n","  Downloading openai-1.59.3-py3-none-any.whl.metadata (27 kB)\n","Collecting tiktoken<1,>=0.7 (from langchain-openai)\n","  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (6.0.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (1.33)\n","Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (0.2.3)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (24.2)\n","Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (2.10.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (9.0.0)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (4.12.2)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.10)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (2024.12.14)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-openai) (3.0.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-openai) (3.10.12)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-openai) (1.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain-openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain-openai) (2.27.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\n","Downloading langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading openai-1.59.3-py3-none-any.whl (454 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tiktoken, openai, langchain-openai\n","  Attempting uninstall: openai\n","    Found existing installation: openai 1.57.4\n","    Uninstalling openai-1.57.4:\n","      Successfully uninstalled openai-1.57.4\n","Successfully installed langchain-openai-0.2.14 openai-1.59.3 tiktoken-0.8.0\n"]}]},{"cell_type":"code","source":["!pip install faiss-cpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"g8nixzVjOUna","executionInfo":{"status":"ok","timestamp":1735948849159,"user_tz":180,"elapsed":11917,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"188c819a-f65f-446d-be68-2640259331b8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting faiss-cpu\n","  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n","Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n","Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: faiss-cpu\n","Successfully installed faiss-cpu-1.9.0.post1\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"id":"6IwzIUH5lE7q","executionInfo":{"status":"ok","timestamp":1735948928471,"user_tz":180,"elapsed":3143,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}}},"outputs":[],"source":["# https://python.langchain.com/v0.2/docs/how_to/embed_text/\n","\n","from langchain_community.vectorstores import FAISS\n","from langchain_openai import OpenAIEmbeddings\n","\n","vectorstore = FAISS.from_documents(all_splits, OpenAIEmbeddings())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fgsypQKolE7t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735321581958,"user_tz":180,"elapsed":668,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"cc5c7b37-f797-4946-bfa5-5eb1c1828323"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["6"]},"metadata":{},"execution_count":10}],"source":["retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n","\n","retrieved_docs = retriever.invoke(\"precisa de doutorado para a vaga?\")\n","\n","len(retrieved_docs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kDBCGqS_lE7u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735321583864,"user_tz":180,"elapsed":380,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"451fbece-70f9-4abf-c360-77266e211f8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requisitos e Qualificações:\n","Doutorado em áreas correlatas;Compreenda e desenvolva modelos de machine learning e deep learning para resolver desafios complexos de cibersegurança;Conhecimento em frameworks de machine learning como TensorFlow, PyTorch ou scikit-learn para desenvolver modelos preditivos e de detecção de anomalias aplicados à cibersegurança;Entenda a arquitetura distribuída dos sistemas e garanta a integração eficiente de soluções de IA com aplicações em cloud;Habilidade em manipulação e visualização de dados com Pandas, NumPy, Matplotlib e Seaborn para explorar grandes volumes de dados;Experiência com AWS, Google Cloud ou Azure para projetar e implementar infraestruturas escaláveis e resilientes;Familiaridade com Kubernetes e Docker para garantir escalabilidade e resiliência de sistemas distribuídos;Experiência com controle de versão (Git) e repositórios remotos como GitLab;Inglês avançado para leitura, escrita e comunicação, facilitando a colaboração com equipes globais.\n"]}],"source":["print(retrieved_docs[0].page_content)"]},{"cell_type":"markdown","metadata":{"id":"iTLAqQkclE7v"},"source":["### Buscando e Recuperando Informações - Retrieve"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JxqhEAGqlE7w"},"outputs":[],"source":["from langchain_core.prompts import ChatPromptTemplate\n","\n","system_template = \"\"\"Você é um assistente para tarefas de perguntas e respostas. Use os seguintes trechos de contexto recuperados para responder à pergunta. Se você não souber a resposta, apenas diga que não sabe. Use no máximo duas frases e mantenha a resposta concisa e fale apenas o necessário.\n","\n","Pergunta: {question}\n","\n","Contexto: {context}\n","\n","Resposta:\n","\"\"\"\n","\n","prompt_template = ChatPromptTemplate.from_template(system_template)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EzJfN7lqlE7x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735321626805,"user_tz":180,"elapsed":323,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"9cd44e46-8159-4b2d-8017-5c010a2f0f21"},"outputs":[{"output_type":"stream","name":"stdout","text":["[HumanMessage(content='Você é um assistente para tarefas de perguntas e respostas. Use os seguintes trechos de contexto recuperados para responder à pergunta. Se você não souber a resposta, apenas diga que não sabe. Use no máximo duas frases e mantenha a resposta concisa e fale apenas o necessário.\\n\\nPergunta: alguma pergunta\\n\\nContexto: algum contexto\\n\\nResposta:\\n', additional_kwargs={}, response_metadata={})]\n"]}],"source":["example_messages = prompt_template.invoke({\n","    \"context\": \"algum contexto\",\n","    \"question\": \"alguma pergunta\"\n","})\n","\n","print(example_messages.to_messages())"]},{"cell_type":"markdown","metadata":{"id":"rD85oVqdlE7y"},"source":["### Gerando Respostas - Generate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9MEuQE06lE7y"},"outputs":[],"source":["from langchain_openai import ChatOpenAI\n","\n","llm = ChatOpenAI(model=\"gpt-4o-mini\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wykBBrmulE7z"},"outputs":[],"source":["from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnablePassthrough\n","\n","def format_docs(docs):\n","    return \"\\n\\n\".join(doc.page_content for doc in docs)\n","\n","rag_chain = (\n","    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n","    | prompt_template\n","    | llm\n","    | StrOutputParser()\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l8EsXgunlE7z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735321662757,"user_tz":180,"elapsed":1187,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"fd144cdf-7491-4f2c-cc2b-5c4d8ffff3c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sim, o CESAR oferece plano de saúde como benefício. Além disso, há também plano odontológico e outros auxílios."]}],"source":["for chunk in rag_chain.stream(\"Tem plano de saúde como benefício?\"):\n","    print(chunk, end=\"\", flush=True)"]},{"cell_type":"markdown","metadata":{"id":"kvftFcFOlE70"},"source":["## Exercícios"]},{"cell_type":"markdown","metadata":{"id":"Tl53y_nXlE70"},"source":["### Exercício 1\n","Faça um RAG com um pequeno arquivo de texto, contendo informações que, certamente, a LLM não conheça. Você deverá construir o arquivo e enviar para o ambiente de execução. Escolha a forma de chunking apropriada para o seu documento."]},{"cell_type":"code","source":["!pip install pypdf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c-s6l4sUO2pm","executionInfo":{"status":"ok","timestamp":1735324201182,"user_tz":180,"elapsed":4517,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"507af0a0-aadb-44fb-f01e-c5b35196269c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pypdf\n","  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n","Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/298.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/298.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pypdf\n","Successfully installed pypdf-5.1.0\n"]}]},{"cell_type":"code","source":["from langchain_community.document_loaders import PyPDFLoader\n","\n","file_path = (\n","    \"Currículo - Manuela Carvalho.pdf\"\n",")\n","loader = PyPDFLoader(file_path)\n","pages = loader.load_and_split()\n","\n","len(pages)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"no4hF1gGYeeI","executionInfo":{"status":"ok","timestamp":1735324369212,"user_tz":180,"elapsed":334,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"bbd8620e-84c8-4b04-866a-c1780848be4e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["from langchain_text_splitters import RecursiveCharacterTextSplitter\n","\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=1000, chunk_overlap=500, add_start_index=True\n",")\n","all_splits = text_splitter.split_documents(pages)\n","\n","len(all_splits)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"erK6K1JXYyFW","executionInfo":{"status":"ok","timestamp":1735325136279,"user_tz":180,"elapsed":362,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"ae874708-8722-4f1c-90f2-c5609c95b7fd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["vectorstore = FAISS.from_documents(all_splits, OpenAIEmbeddings())\n","retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n","\n","retrieved_docs = retriever.invoke(\"quais são os conhecimentos dessa pessoa?\")\n","\n","len(retrieved_docs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jBWO-sl9Z61R","executionInfo":{"status":"ok","timestamp":1735325147480,"user_tz":180,"elapsed":636,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"fbcb2cf7-e438-4331-842e-f62f1f969ac4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["system_template = \"\"\"Você é um assistente para tarefas de perguntas e respostas. Use os seguintes trechos de contexto recuperados para responder à pergunta. Se você não souber a resposta, apenas diga que não sabe. Use no máximo duas frases e mantenha a resposta concisa e fale apenas o necessário.\n","\n","Pergunta: {question}\n","\n","Contexto: {context}\n","\n","Resposta:\n","\"\"\"\n","\n","prompt_template = ChatPromptTemplate.from_template(system_template)"],"metadata":{"id":"UOOgA_IybSNp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["llm = ChatOpenAI(model=\"gpt-4o-mini\")"],"metadata":{"id":"QaoSmy6hbZmW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def format_docs(docs):\n","    return \"\\n\\n\".join(doc.page_content for doc in docs)\n","\n","rag_chain = (\n","    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n","    | prompt_template\n","    | llm\n","    | StrOutputParser()\n",")"],"metadata":{"id":"gRzKO6olbdre"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for chunk in rag_chain.stream(\"quais são os conhecimentos dessa pessoa?\"):\n","    print(chunk, end=\"\", flush=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZKv15YhQamhY","executionInfo":{"status":"ok","timestamp":1735325157819,"user_tz":180,"elapsed":1593,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"5378729f-7d23-47b2-8196-d3355bd8c004"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Manuela possui conhecimentos em programação, incluindo Java, Spring Boot, JSF, HTML, CSS, Angular, PHP e Laravel, além de inglês intermediário. Ela também tem formação em Análise e Desenvolvimento de Sistemas e especialização em Engenharia e Análise de Dados."]}]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}