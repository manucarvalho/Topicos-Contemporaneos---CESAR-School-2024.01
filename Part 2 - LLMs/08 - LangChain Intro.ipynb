{"cells":[{"cell_type":"markdown","source":["Aluna: Manuela de Lacerda Bezerra Carvalho (mlbc@cesar.school)"],"metadata":{"id":"ctvkaMYC9ySR"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"R02BoEaBhpT4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735949076509,"user_tz":180,"elapsed":6336,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"8a57e1a1-6e13-471a-b7e6-8979aa1769a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["··········\n"]}],"source":["import getpass\n","import os\n","\n","os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"]},{"cell_type":"markdown","metadata":{"id":"34l290uOhpUE"},"source":["## Modelos"]},{"cell_type":"code","source":["!pip install langchain langchain_openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"dg7J_C9a3sds","executionInfo":{"status":"ok","timestamp":1735949094476,"user_tz":180,"elapsed":6285,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"1c5654a5-b6f9-42c4-8175-2419a30e9966"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.12)\n","Collecting langchain_openai\n","  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.25 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.25)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n","Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n","Collecting langchain-core<0.4.0,>=0.3.25 (from langchain)\n","  Downloading langchain_core-0.3.29-py3-none-any.whl.metadata (6.3 kB)\n","Collecting openai<2.0.0,>=1.58.1 (from langchain_openai)\n","  Downloading openai-1.59.3-py3-none-any.whl.metadata (27 kB)\n","Collecting tiktoken<1,>=0.7 (from langchain_openai)\n","  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (1.2.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain) (3.0.0)\n","Downloading langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.3.29-py3-none-any.whl (411 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading openai-1.59.3-py3-none-any.whl (454 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tiktoken, openai, langchain-core, langchain_openai\n","  Attempting uninstall: openai\n","    Found existing installation: openai 1.57.4\n","    Uninstalling openai-1.57.4:\n","      Successfully uninstalled openai-1.57.4\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.3.25\n","    Uninstalling langchain-core-0.3.25:\n","      Successfully uninstalled langchain-core-0.3.25\n","Successfully installed langchain-core-0.3.29 langchain_openai-0.2.14 openai-1.59.3 tiktoken-0.8.0\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"uoJSVJqShpUK","executionInfo":{"status":"ok","timestamp":1735949106446,"user_tz":180,"elapsed":2722,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}}},"outputs":[],"source":["from langchain_openai import ChatOpenAI\n","\n","llm = ChatOpenAI(model=\"gpt-4o-mini\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"7uAzZBAMhpUN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735949109899,"user_tz":180,"elapsed":993,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"46e290e4-1df2-49f2-d620-be72395cf08b"},"outputs":[{"output_type":"stream","name":"stdout","text":["content='Olá! Como posso ajudar você hoje?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None} id='run-d9eecd26-e958-4f86-b95b-dd0adf2f3c2b-0' usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"]}],"source":["response = llm.invoke(\"Olá\")\n","\n","print(response)"]},{"cell_type":"markdown","metadata":{"id":"cMIMauJ5hpUP"},"source":["## Prompts"]},{"cell_type":"markdown","metadata":{"id":"2OpEjfKKhpUQ"},"source":[]},{"cell_type":"markdown","metadata":{"id":"s381_0t_hpUQ"},"source":["### Templates Simples"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Pg7dRu7chpUR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735950041423,"user_tz":180,"elapsed":366,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"e0a0fa71-2f69-4cef-a5f0-993bb9a5e2b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["messages=[HumanMessage(content='Traduza o seguinte texto para português: Artificial Intelligence is the future!', additional_kwargs={}, response_metadata={})]\n"]}],"source":["from langchain_core.prompts import ChatPromptTemplate\n","\n","prompt_template = ChatPromptTemplate.from_template(\"Traduza o seguinte texto para português: {texto}\")\n","\n","prompt = prompt_template.invoke({\"texto\": \"Artificial Intelligence is the future!\"})\n","print(prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qwxBzJ63hpUS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735064190033,"user_tz":180,"elapsed":647,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"2d5b3cdc-c41d-4c4b-8e8f-24a211438a23"},"outputs":[{"output_type":"stream","name":"stdout","text":["Inteligência Artificial é o futuro!\n"]}],"source":["response = llm.invoke(prompt)\n","\n","print(response.content)"]},{"cell_type":"markdown","metadata":{"id":"EkbLt3EkhpUT"},"source":["### Templates de Mensagens"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"etqU-nsphpUU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735064214485,"user_tz":180,"elapsed":612,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"bc3cd567-e560-40b1-a59b-f9fb3e8dbaef"},"outputs":[{"output_type":"stream","name":"stdout","text":["content='Olá, como você está?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 36, 'total_tokens': 43, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_d02d531b47', 'finish_reason': 'stop', 'logprobs': None} id='run-924a1a7b-97f1-4766-90e7-5bd98f7efbc2-0' usage_metadata={'input_tokens': 36, 'output_tokens': 7, 'total_tokens': 43, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"]}],"source":["from langchain_core.messages import SystemMessage, HumanMessage\n","\n","messages = [\n","    SystemMessage(content=\"Você é um tradutor de inglês para português. Traduza as mensagens que forem enviadas.\"),\n","    HumanMessage(content=\"Hello, how are you?\"),\n","]\n","\n","# messages = [\n","#     (\"system\", \"Você é um tradutor de inglês para português. Traduza as mensagens que forem enviadas.\"),\n","#     (\"human\", \"Hello, how are you?\"),\n","# ]\n","\n","response = llm.invoke(messages)\n","\n","print(response)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zHG0nI88hpUV"},"outputs":[],"source":["prompt_template = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", \"Você é um tradutor de {lingua_origem} para {lingua_destino}. Traduza as mensagens que forem enviadas.\"),\n","        (\"user\", \"{texto}\")\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sOYfpC1ThpUW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735064242627,"user_tz":180,"elapsed":329,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"a595434c-349c-4bf6-830e-eb4f5789fa25"},"outputs":[{"output_type":"stream","name":"stdout","text":["messages=[SystemMessage(content='Você é um tradutor de inglês para português. Traduza as mensagens que forem enviadas.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you?', additional_kwargs={}, response_metadata={})]\n"]}],"source":["prompt = prompt_template.invoke({\n","    \"lingua_origem\": \"inglês\",\n","    \"lingua_destino\": \"português\",\n","    \"texto\": \"Hello, how are you?\"\n","})\n","\n","print(prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"it5bHFrihpUX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735064249261,"user_tz":180,"elapsed":617,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"fba4a21d-90df-402d-fbc7-d42ef2ef88d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Olá, como você está?\n"]}],"source":["response = llm.invoke(prompt)\n","\n","print(response.content)"]},{"cell_type":"markdown","metadata":{"id":"b_rpLxz8hpUY"},"source":["### Parsers"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"A-FT8R5ThpUZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735950061344,"user_tz":180,"elapsed":626,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"bbcbd367-d03f-41cf-bb7e-ee247a2dadc1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Resposta:\n","content='A capital do Rio Grande do Norte é Natal.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 16, 'total_tokens': 27, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None} id='run-30eebf12-74f9-4236-99b1-c0e5f101f9c2-0' usage_metadata={'input_tokens': 16, 'output_tokens': 11, 'total_tokens': 27, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n","\n","Saída do parser:\n","A capital do Rio Grande do Norte é Natal.\n"]}],"source":["from langchain_core.output_parsers import StrOutputParser\n","\n","str_parser = StrOutputParser()\n","\n","response = llm.invoke(\"Qual a capital do Rio Grande do Norte?\")\n","output = str_parser.invoke(response)\n","\n","print(\"Resposta:\")\n","print(response)\n","print()\n","print(\"Saída do parser:\")\n","print(output)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Yesy-tbhpUb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735064291510,"user_tz":180,"elapsed":3100,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"2a646ee9-368c-4ed7-c9ca-12194de11ed6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Resposta:\n","content='Aqui está a representação em formato JSON das partículas que constituem o átomo, incluindo suas massas e cargas:\\n\\n```json\\n{\\n  \"próton\": {\\n    \"massa\": \"1.6726 x 10^-27 kg\",\\n    \"carga\": \"+1 e\"\\n  },\\n  \"nêutron\": {\\n    \"massa\": \"1.6750 x 10^-27 kg\",\\n    \"carga\": \"0 e\"\\n  },\\n  \"elétron\": {\\n    \"massa\": \"9.1094 x 10^-31 kg\",\\n    \"carga\": \"-1 e\"\\n  }\\n}\\n```\\n\\nNeste JSON, \"e\" representa a carga elementar, que é aproximadamente \\\\(1.602 \\\\times 10^{-19}\\\\) coulombs.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 162, 'prompt_tokens': 38, 'total_tokens': 200, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None} id='run-484116dd-7197-48ac-b683-1342fcff621d-0' usage_metadata={'input_tokens': 38, 'output_tokens': 162, 'total_tokens': 200, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n","\n","Saída do parser:\n","{'próton': {'massa': '1.6726 x 10^-27 kg', 'carga': '+1 e'}, 'nêutron': {'massa': '1.6750 x 10^-27 kg', 'carga': '0 e'}, 'elétron': {'massa': '9.1094 x 10^-31 kg', 'carga': '-1 e'}}\n"]}],"source":["from langchain_core.output_parsers import JsonOutputParser\n","\n","json_parser = JsonOutputParser()\n","\n","response = llm.invoke(\"Quais as massas e cargas das partículas que constituem o átomo? Responda no formato JSON em que cada chave seja o nome da partícula\")\n","output = json_parser.invoke(response)\n","\n","print(\"Resposta:\")\n","print(response)\n","print()\n","print(\"Saída do parser:\")\n","print(output)"]},{"cell_type":"markdown","metadata":{"id":"8w4Jym-ghpUb"},"source":["## Encadeamento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"erYr_FNlhpUc"},"outputs":[],"source":["chain = prompt_template | llm | StrOutputParser()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JI5dVloahpUc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735064321745,"user_tz":180,"elapsed":687,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"e8fd81cc-3882-4464-8d14-9e1196d250d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["¡Las playas de Recife tienen tiburones!\n"]}],"source":["response = chain.invoke({\n","    \"lingua_origem\": \"inglês\",\n","    \"lingua_destino\": \"espanhol\",\n","    \"texto\": \"As praias de Recife tem tubarões!\"\n","})\n","\n","print(response)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0c7naGr-hpUc"},"outputs":[],"source":["def translate(texto, lingua_origem, lingua_destino):\n","    response = chain.invoke({\n","        \"lingua_origem\": lingua_origem,\n","        \"lingua_destino\": lingua_destino,\n","        \"texto\": texto\n","    })\n","    return response"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r6YraHNJhpUd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735064347680,"user_tz":180,"elapsed":1409,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"8943a298-8aea-4202-8dcb-86f188aae3a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["¡Las playas de Recife tienen tiburones!\n"]}],"source":["output = translate(\"The beaches of Recife have sharks!\", \"inglês\", \"espanhol\")\n","\n","print(output)"]},{"cell_type":"markdown","metadata":{"id":"xyw-XGFWhpUd"},"source":["## Exercícios"]},{"cell_type":"markdown","metadata":{"id":"7MydmurBhpUe"},"source":["### Exercício 1\n","Crie uma `chain` que a partir de um tópico informado pelo usuário, crie uma piada."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0AWMsYMphpUe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735064662461,"user_tz":180,"elapsed":1178,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"99442bec-c56f-4556-83fe-fe68b38d7bc7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Por que o Natal é o melhor dia para se contar piadas?\n","\n","Porque é quando todo mundo já está \"no clima\" e \"pronto para o riso\" com as luzes e os presentes! 🎄😄\n"]}],"source":["prompt_template_1 = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", \"Crie uma piada para o tema.\"),\n","        (\"user\", \"{tema}\")\n","    ]\n",")\n","\n","chain_1 = prompt_template_1 | llm | StrOutputParser()\n","response_1 = chain_1.invoke({\n","    \"tema\": \"Natal\"\n","})\n","\n","print(response_1)"]},{"cell_type":"markdown","metadata":{"id":"8wxTRoJehpUe"},"source":["### Exercício 2\n","Crie uma `chain` que classifique o sentimento de um texto de entrada em positivo, neutro ou negativo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7AFHzw6nhpUe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735064793357,"user_tz":180,"elapsed":585,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"72840017-3a3f-4a55-eb31-2a4ca34240d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Positivo\n"]}],"source":["prompt_template_2 = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", \"Classifique o sentimento do texto em positivo, neutro ou negativo.\"),\n","        (\"user\", \"{texto}\")\n","    ]\n",")\n","\n","chain_2 = prompt_template_2 | llm | StrOutputParser()\n","response_2 = chain_2.invoke({\n","    \"texto\": \"Estou de férias.\"\n","})\n","\n","print(response_2)"]},{"cell_type":"markdown","metadata":{"id":"YViRRCtyhpUf"},"source":["### Exercício 3\n","Crie uma `chain` que gere o código de uma função Python de acordo com a descrição do usuário."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kJDu3plohpUf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735064925282,"user_tz":180,"elapsed":4361,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"33625b5b-70c1-440d-e2cb-4f50ef781e89"},"outputs":[{"output_type":"stream","name":"stdout","text":["Claro! Aqui está um código em Python que define uma função para calcular a média de dois números fornecidos pelo usuário:\n","\n","```python\n","def calcular_media(num1, num2):\n","    return (num1 + num2) / 2\n","\n","def main():\n","    # Solicita ao usuário que insira dois números\n","    try:\n","        numero1 = float(input(\"Digite o primeiro número: \"))\n","        numero2 = float(input(\"Digite o segundo número: \"))\n","        \n","        # Calcula a média\n","        media = calcular_media(numero1, numero2)\n","        \n","        # Exibe o resultado\n","        print(f\"A média de {numero1} e {numero2} é: {media}\")\n","    except ValueError:\n","        print(\"Por favor, insira valores numéricos válidos.\")\n","\n","if __name__ == \"__main__\":\n","    main()\n","```\n","\n","### Como funciona:\n","1. A função `calcular_media` recebe dois parâmetros (`num1` e `num2`) e retorna a média deles.\n","2. A função `main` solicita que o usuário insira dois números, converte esses valores para `float` e chama a função `calcular_media`.\n","3. O resultado é exibido na tela.\n","4. Um tratamento de exceção é adicionado para garantir que o usuário insira valores numéricos válidos.\n","\n","Você pode copiar e colar esse código em um arquivo Python e executá-lo para calcular a média de dois números!\n"]}],"source":["prompt_template_3 = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", \"Crie o código de uma função em python que calcule a média de dois números passados pelo o usuário.\"),\n","    ]\n",")\n","\n","chain_3 = prompt_template_3 | llm | StrOutputParser()\n","response_3 = chain_3.invoke({})\n","\n","print(response_3)"]},{"cell_type":"markdown","metadata":{"id":"bxRuwbKehpUf"},"source":["### Exercício 4\n","Crie uma `chain` que explique de forma simplificada um tópico geral fornecido pelo usuário e, em seguida, traduza a explicação para inglês. Utilize dois templates encadeados."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"szSOnvhqhpUg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735951521261,"user_tz":180,"elapsed":8832,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"3a1600e0-cec3-4976-9b04-30974171b292"},"outputs":[{"output_type":"stream","name":"stdout","text":["Christmas is a Christian celebration that takes place on December 25th and commemorates the birth of Jesus Christ. It is one of the most important holidays in many countries around the world, marking a time of joy, fellowship, and reflection.\n","\n","Christmas traditions vary from place to place, but some of the most common include:\n","\n","1. **Decorations**: People often decorate their homes with lights, Christmas trees, garlands, and ornaments.\n","\n","2. **Christmas Dinner**: It is common to gather family and friends for a large meal, which may include traditional dishes such as turkey, French toast, and panettone.\n","\n","3. **Gifts**: Exchanging gifts is an important part of Christmas, symbolizing generosity and love.\n","\n","4. **Carols and Songs**: Many people sing Christmas songs that talk about the spirit of Christmas and the birth of Jesus.\n","\n","5. **Santa Claus**: In various cultures, the figure of Santa Claus is associated with Christmas, bringing gifts to children.\n","\n","Additionally, Christmas is also a time when many reflect on values such as peace, love, and solidarity.\n"]}],"source":["prompt_template_4 = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", \"Explique de forma simplificada o tópico {topico}\"),\n","        (\"user\", \"{topico}\")\n","    ]\n",")\n","prompt_template_5 = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", \"Traduza o texto para inglês.\"),\n","        (\"user\", \"{texto}\")\n","    ]\n",")\n","\n","chain_4 = prompt_template_4 | llm | prompt_template_5 | llm | StrOutputParser()\n","\n","response_4 = chain_4.invoke({\n","    \"topico\":\"Natal\"\n","})\n","\n","print(response_4)"]},{"cell_type":"markdown","metadata":{"id":"YuT_2W9_hpUg"},"source":["### Exercício 5 - Desafio\n","Crie uma `chain` que responda perguntas sobre o CESAR School."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hm9ueXwrhpUg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735066551372,"user_tz":180,"elapsed":8227,"user":{"displayName":"MANUELA DE LACERDA BEZERRA CARVALHO","userId":"16913470037089929737"}},"outputId":"12e73007-55e9-4a0a-c942-b2ebeb38ebe9"},"outputs":[{"output_type":"stream","name":"stdout","text":["A Cesar School é uma instituição de ensino localizada no Brasil, conhecida por oferecer cursos voltados para a formação em tecnologia, inovação e design. Ela faz parte do grupo Cesar, que é uma organização focada em promover a inovação e o desenvolvimento de soluções tecnológicas.\n","\n","A Cesar School oferece programas de pós-graduação, cursos de extensão e treinamentos em áreas como desenvolvimento de software, inteligência artificial, design de interação, entre outros. A escola busca preparar os alunos para os desafios do mercado de trabalho, proporcionando uma combinação de teoria e prática, além de incentivar a criatividade e o pensamento crítico.\n","\n","A instituição destaca-se por sua abordagem prática e colaborativa, muitas vezes envolvendo projetos reais e parcerias com empresas do setor. Isso a torna uma opção atrativa para profissionais que desejam aprimorar suas habilidades e se manter atualizados em um campo em constante evolução.\n"]}],"source":["prompt_template_5 = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", \"O que é a Cesar School?\"),\n","    ]\n",")\n","\n","chain_5 = prompt_template_5 | llm | StrOutputParser()\n","response_5 = chain_5.invoke({})\n","\n","print(response_5)"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}